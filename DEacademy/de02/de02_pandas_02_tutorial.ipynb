{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a04f56d6",
   "metadata": {},
   "source": [
    "# 用SQL語法來理解pandas\n",
    "\n",
    "由於大多數學習使用pandas的許多學員對SQL都有一定的了解，因此以下提供一些範例來說明如何使用pandas來執行各種SQL的操作。\n",
    "\n",
    "按照慣例，我們按以下方式導入pandas和NumPy："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181ff624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2554f59f",
   "metadata": {},
   "source": [
    "大多數範例將利用在一個範例數據集`tips.csv`。我們將數據讀入一個名為`tips`的DataFrame中，並假定我們具有相同名稱和結構的數據庫資料表。\n",
    "\n",
    "* total_bill 帳單總金額\n",
    "* tip 小費\n",
    "* sex 姓別\n",
    "* smoker 是否有吸煙\n",
    "* day 星期幾\n",
    "* time 午餐/晚餐\n",
    "* size 用餐人數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64365e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   total_bill  244 non-null    float64\n",
      " 1   tip         244 non-null    float64\n",
      " 2   sex         244 non-null    object \n",
      " 3   smoker      244 non-null    object \n",
      " 4   day         244 non-null    object \n",
      " 5   time        244 non-null    object \n",
      " 6   size        244 non-null    int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 13.5+ KB\n",
      "None\n",
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n"
     ]
    }
   ],
   "source": [
    "tips = pd.read_csv(\"data/tips.csv\")\n",
    "\n",
    "print(tips.info())\n",
    "\n",
    "print(tips.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2892737",
   "metadata": {},
   "source": [
    "## SELECT\n",
    "\n",
    "在SQL中，`SELECT`是使用你要選擇的列的逗號分隔列表（或使用*來選擇所有列）來完成的：\n",
    "\n",
    "```sql\n",
    "SELECT total_bill, tip, smoker, time\n",
    "FROM tips\n",
    "LIMIT 5;\n",
    "```\n",
    "\n",
    "對於pandas，通過將column names列表傳遞給DataFrame來完成列選擇："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8491f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip smoker    time\n",
      "0       16.99  1.01     No  Dinner\n",
      "1       10.34  1.66     No  Dinner\n",
      "2       21.01  3.50     No  Dinner\n",
      "3       23.68  3.31     No  Dinner\n",
      "4       24.59  3.61     No  Dinner\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "results = tips[[\"total_bill\", \"tip\", \"smoker\", \"time\"]].head(5)\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d1124b",
   "metadata": {},
   "source": [
    "調用不帶列名列表的DataFrame會顯示所有列（類似於SQL的 *）。\n",
    "\n",
    "在SQL中，你可以添加一個計算列：\n",
    "\n",
    "```sql\n",
    "SELECT *, tip/total_bill as tip_rate\n",
    "FROM tips\n",
    "LIMIT 5;\n",
    "```\n",
    "\n",
    "對於pandas，可以使用DataFrame的`DataFrame.assign()`方法增加一個新列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c297f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   total_bill  244 non-null    float64\n",
      " 1   tip         244 non-null    float64\n",
      " 2   sex         244 non-null    object \n",
      " 3   smoker      244 non-null    object \n",
      " 4   day         244 non-null    object \n",
      " 5   time        244 non-null    object \n",
      " 6   size        244 non-null    int64  \n",
      " 7   tip_rate    244 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 15.4+ KB\n",
      "None\n",
      "   total_bill   tip     sex smoker  day    time  size  tip_rate\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2  0.059447\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3  0.160542\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3  0.166587\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2  0.139780\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4  0.146808\n"
     ]
    }
   ],
   "source": [
    "results = tips.assign(tip_rate=tips[\"tip\"]/tips[\"total_bill\"])\n",
    "\n",
    "print(results.info())\n",
    "\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a98d0f",
   "metadata": {},
   "source": [
    "## WHERE\n",
    "\n",
    "通過`WHERE`子句在SQL中對數據進行過濾(filtering)。\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM tips\n",
    "WHERE time = 'Dinner'\n",
    "LIMIT 5;\n",
    "```\n",
    "\n",
    "DataFrame可以通過多種方式進行過濾。最直觀的是使用[boolean indexing](https://pandas.pydata.org/docs/user_guide/indexing.html#indexing-boolean)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82bffc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 176 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   total_bill  176 non-null    float64\n",
      " 1   tip         176 non-null    float64\n",
      " 2   sex         176 non-null    object \n",
      " 3   smoker      176 non-null    object \n",
      " 4   day         176 non-null    object \n",
      " 5   time        176 non-null    object \n",
      " 6   size        176 non-null    int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 11.0+ KB\n",
      "None\n",
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n"
     ]
    }
   ],
   "source": [
    "results = tips[tips[\"time\"] == \"Dinner\"]\n",
    "\n",
    "print(results.info())\n",
    "\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a27a7e",
   "metadata": {},
   "source": [
    "上面的語法只是將一個`Series`的True/False傳遞給DataFrame，並返回所有帶有True的row。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9123ee8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "0      True\n",
      "1      True\n",
      "2      True\n",
      "3      True\n",
      "4      True\n",
      "       ... \n",
      "239    True\n",
      "240    True\n",
      "241    True\n",
      "242    True\n",
      "243    True\n",
      "Name: time, Length: 244, dtype: bool\n",
      "True     176\n",
      "False     68\n",
      "Name: time, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "is_dinner = tips[\"time\"] == \"Dinner\"\n",
    "\n",
    "print(type(is_dinner))\n",
    "\n",
    "print(is_dinner)\n",
    "\n",
    "print(is_dinner.value_counts()) # 透過 value_counts()來取得取的統計"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47112e58",
   "metadata": {},
   "source": [
    "就像SQL的`OR`和`AND`一樣，可以使用`|`(OR) 與 `&` (AND)將多個條件傳遞給DataFrame。\n",
    "\n",
    "```sql\n",
    "-- 小費大於 $5.00 並且用餐時間是 'Dinner' \n",
    "SELECT *\n",
    "FROM tips\n",
    "WHERE time = 'Dinner' AND tip > 5.00;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaa0df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15 entries, 23 to 239\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   total_bill  15 non-null     float64\n",
      " 1   tip         15 non-null     float64\n",
      " 2   sex         15 non-null     object \n",
      " 3   smoker      15 non-null     object \n",
      " 4   day         15 non-null     object \n",
      " 5   time        15 non-null     object \n",
      " 6   size        15 non-null     int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 960.0+ bytes\n",
      "None\n",
      "    total_bill   tip     sex smoker  day    time  size\n",
      "23       39.42  7.58    Male     No  Sat  Dinner     4\n",
      "44       30.40  5.60    Male     No  Sun  Dinner     4\n",
      "47       32.40  6.00    Male     No  Sun  Dinner     4\n",
      "52       34.81  5.20  Female     No  Sun  Dinner     4\n",
      "59       48.27  6.73    Male     No  Sat  Dinner     4\n"
     ]
    }
   ],
   "source": [
    "# tips of more than $5.00 at Dinner meals\n",
    "results = tips[(tips[\"time\"]==\"Dinner\") & (tips[\"tip\"] > 5.00)]\n",
    "\n",
    "print(results.info())\n",
    "\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064516f0",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- 用餐人數至少有 5人或是總金額大於 45\n",
    "SELECT *\n",
    "FROM tips\n",
    "WHERE size >= 5 OR total_bill > 45;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff3d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13 entries, 59 to 216\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   total_bill  13 non-null     float64\n",
      " 1   tip         13 non-null     float64\n",
      " 2   sex         13 non-null     object \n",
      " 3   smoker      13 non-null     object \n",
      " 4   day         13 non-null     object \n",
      " 5   time        13 non-null     object \n",
      " 6   size        13 non-null     int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 832.0+ bytes\n",
      "None\n",
      "     total_bill   tip     sex smoker   day    time  size\n",
      "59        48.27  6.73    Male     No   Sat  Dinner     4\n",
      "125       29.80  4.20  Female     No  Thur   Lunch     6\n",
      "141       34.30  6.70    Male     No  Thur   Lunch     6\n",
      "142       41.19  5.00    Male     No  Thur   Lunch     5\n",
      "143       27.05  5.00  Female     No  Thur   Lunch     6\n"
     ]
    }
   ],
   "source": [
    "results = tips[(tips[\"size\"] >= 5) | (tips[\"total_bill\"] > 45)]\n",
    "\n",
    "print(results.info())\n",
    "\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670a421",
   "metadata": {},
   "source": [
    "NULL檢查是使用`notna()`和`isna()`方法完成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e2ea28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   col1    4 non-null      object\n",
      " 1   col2    4 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 208.0+ bytes\n",
      "None\n",
      "  col1 col2\n",
      "0    A    F\n",
      "1    B  NaN\n",
      "2  NaN    G\n",
      "3    C    H\n",
      "4    D    I\n"
     ]
    }
   ],
   "source": [
    "df_tmp = pd.DataFrame(\n",
    "     {\n",
    "         \"col1\": [\"A\", \"B\", np.NaN, \"C\", \"D\"], \n",
    "         \"col2\": [\"F\", np.NaN, \"G\", \"H\", \"I\"]\n",
    "     }\n",
    ")\n",
    "\n",
    "print(df_tmp.info())\n",
    "print(df_tmp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd6cd17",
   "metadata": {},
   "source": [
    "假設我們有一個與上面的DataFrame具有相同結構的資料表。通過以下查詢，我們只能看到col2為NULL的記錄：\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM frame\n",
    "WHERE col2 IS NULL;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92fc63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1 col2\n",
      "1    B  NaN\n"
     ]
    }
   ],
   "source": [
    "results = df_tmp[df_tmp[\"col2\"].isna()]\n",
    "\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a32809",
   "metadata": {},
   "source": [
    "可以使用`notna()`來獲取`col1`不為`null`的資料。\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM frame\n",
    "WHERE col1 IS NOT NULL;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efe4970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1 col2\n",
      "0    A    F\n",
      "1    B  NaN\n",
      "3    C    H\n",
      "4    D    I\n"
     ]
    }
   ],
   "source": [
    "results = df_tmp[df_tmp[\"col1\"].notna()]\n",
    "\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad08784",
   "metadata": {},
   "source": [
    "## GROUP BY\n",
    "\n",
    "在pandas中，SQL的`GROUP BY`操作是使用類似命名的`groupby()`方法執行的。 `groupby()`通常是指一個過程，我們希望將數據集劃分為多個組，應用某些功能函數（通常是aggregation）。\n",
    "\n",
    "常見的SQL操作是獲取整個數據集中每個組中的記錄數。例如，通過查詢可以了解不同性別會給予的小費人數：\n",
    "\n",
    "```sql\n",
    "SELECT sex, count(*)\n",
    "FROM tips\n",
    "GROUP BY sex;\n",
    "/*\n",
    "Female     87\n",
    "Male      157\n",
    "*/\n",
    "```\n",
    "\n",
    "在pandas裡可以這麼做:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5359dd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "Female     87\n",
      "Male      157\n",
      "dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "results = tips.groupby(\"sex\").size()\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89eb614",
   "metadata": {},
   "source": [
    "注意，在以上的範例中，我們使用`size()`而不是`count()`。這是因為`count()`函數會返回每個column中`not null`的資料筆數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42e0c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        total_bill  tip  smoker  day  time  size\n",
      "sex                                             \n",
      "Female          87   87      87   87    87    87\n",
      "Male           157  157     157  157   157   157\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "results = tips.groupby(\"sex\").count()\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9410a",
   "metadata": {},
   "source": [
    "或者，我們可以將`count()`方法應用於指定的column："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef5345d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "Female     87\n",
      "Male      157\n",
      "Name: total_bill, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "results = tips.groupby(\"sex\")[\"total_bill\"].count()\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1879a8",
   "metadata": {},
   "source": [
    "當然我們也可以一次地套用多種functions。舉例來說，假設我們想了解小費金額在一周中的一天之間有何不同-`agg()`可讓我們達到這個目的。\n",
    "\n",
    "```sql\n",
    "SELECT day, AVG(tip), COUNT(*)\n",
    "FROM tips\n",
    "GROUP BY day;\n",
    "/*\n",
    "Fri   2.734737   19\n",
    "Sat   2.993103   87\n",
    "Sun   3.255132   76\n",
    "Thur  2.771452   62\n",
    "*/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44e16ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tip  day\n",
      "day                \n",
      "Fri   2.734737   19\n",
      "Sat   2.993103   87\n",
      "Sun   3.255132   76\n",
      "Thur  2.771452   62\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "results = tips.groupby(\"day\").agg({\"tip\":np.mean, \"day\": np.size})\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97fc2d4",
   "metadata": {},
   "source": [
    "通過將多個列的列表傳遞給`groupby()`方法，可以完成對多個列的分組。\n",
    "\n",
    "```sql\n",
    "SELECT smoker, day, COUNT(*), AVG(tip)\n",
    "FROM tips\n",
    "GROUP BY smoker, day;\n",
    "/*\n",
    "smoker day\n",
    "No     Fri      4  2.812500\n",
    "       Sat     45  3.102889\n",
    "       Sun     57  3.167895\n",
    "       Thur    45  2.673778\n",
    "Yes    Fri     15  2.714000\n",
    "       Sat     42  2.875476\n",
    "       Sun     19  3.516842\n",
    "       Thur    17  3.030000\n",
    "*/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b043525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              tip          \n",
      "             size      mean\n",
      "smoker day                 \n",
      "No     Fri    4.0  2.812500\n",
      "       Sat   45.0  3.102889\n",
      "       Sun   57.0  3.167895\n",
      "       Thur  45.0  2.673778\n",
      "Yes    Fri   15.0  2.714000\n",
      "       Sat   42.0  2.875476\n",
      "       Sun   19.0  3.516842\n",
      "       Thur  17.0  3.030000\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "results = tips.groupby([\"smoker\", \"day\"]).agg({\"tip\": [np.size, np.mean]})\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ba473",
   "metadata": {},
   "source": [
    "## JOIN\n",
    "\n",
    "可以使用`join()`或`merge()`來執行JOIN。預設情況下，`join()`將在其索引上聯接DataFrame。透過參數設定可讓你指定要執行JOIN的類型（LEFT，RIGHT，INNER，FULL）或要聯接的列（列名或索引）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f970b530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key     value\n",
      "0   A -0.476651\n",
      "1   B -0.908579\n",
      "2   C -0.822806\n",
      "3   D  1.052995\n",
      "  key     value\n",
      "0   B  0.000644\n",
      "1   D -0.018976\n",
      "2   D -0.489452\n",
      "3   E -0.063446\n"
     ]
    }
   ],
   "source": [
    "# generate two dataframe\n",
    "df1 = pd.DataFrame({\"key\": [\"A\", \"B\", \"C\", \"D\"], \"value\": np.random.randn(4)})\n",
    "\n",
    "df2 = pd.DataFrame({\"key\": [\"B\", \"D\", \"D\", \"E\"], \"value\": np.random.randn(4)})\n",
    "\n",
    "print(df1)\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85690839",
   "metadata": {},
   "source": [
    "假設我們有兩個數據庫資料表，它們的名稱和結構與我們創建的DataFrames相同。\n",
    "\n",
    "現在，讓我們看一下各種類型的JOIN。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6ac67",
   "metadata": {},
   "source": [
    "### INNER JOIN\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM df1\n",
    "INNER JOIN df2\n",
    "  ON df1.key = df2.key;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e12956ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   value_x   value_y\n",
      "0   B -0.908579  0.000644\n",
      "1   D  1.052995 -0.018976\n",
      "2   D  1.052995 -0.489452\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# merge performs an INNER JOIN by default\n",
    "results = pd.merge(df1, df2, on=\"key\")\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ab1dd",
   "metadata": {},
   "source": [
    "`merge()`還提供了一些參數，用於將一個DataFrame的列與另一個DataFrame的索引連接在一起的情況。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeeaae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   value_x   value_y\n",
      "1   B -0.908579  0.000644\n",
      "3   D  1.052995 -0.018976\n",
      "3   D  1.052995 -0.489452\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "indexed_df2 = df2.set_index(\"key\")\n",
    "\n",
    "results = pd.merge(df1, indexed_df2, left_on=\"key\", right_index=True)\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478e01d",
   "metadata": {},
   "source": [
    "### LEFT OUTER JOIN\n",
    "\n",
    "```sql\n",
    "-- show all records from df1\n",
    "SELECT *\n",
    "FROM df1\n",
    "LEFT OUTER JOIN df2\n",
    "  ON df1.key = df2.key;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "691636d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   value_x   value_y\n",
      "0   A -0.476651       NaN\n",
      "1   B -0.908579  0.000644\n",
      "2   C -0.822806       NaN\n",
      "3   D  1.052995 -0.018976\n",
      "4   D  1.052995 -0.489452\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# show all records from df1\n",
    "results = pd.merge(df1, df2, on=\"key\", how=\"left\")\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5bb4e0",
   "metadata": {},
   "source": [
    "### RIGHT JOIN\n",
    "\n",
    "```sql\n",
    "-- show all records from df2\n",
    "SELECT *\n",
    "FROM df1\n",
    "RIGHT OUTER JOIN df2\n",
    "  ON df1.key = df2.key;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dd86a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   value_x   value_y\n",
      "0   B -0.908579  0.000644\n",
      "1   D  1.052995 -0.018976\n",
      "2   D  1.052995 -0.489452\n",
      "3   E       NaN -0.063446\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# show all records from df2\n",
    "results = pd.merge(df1, df2, on=\"key\", how=\"right\")\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ebaae1",
   "metadata": {},
   "source": [
    "### FULL JOIN\n",
    "\n",
    "pandas還允許FULL JOIN，它們顯示數據集的兩側，無論連接的列是否找到匹配項。其實並非所有RDBMS（MySQL）都支持FULL JOIN。\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM df1\n",
    "FULL OUTER JOIN df2\n",
    "  ON df1.key = df2.key;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "440be872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   value_x   value_y\n",
      "0   A -0.476651       NaN\n",
      "1   B -0.908579  0.000644\n",
      "2   C -0.822806       NaN\n",
      "3   D  1.052995 -0.018976\n",
      "4   D  1.052995 -0.489452\n",
      "5   E       NaN -0.063446\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# show all records from both frames\n",
    "results = pd.merge(df1, df2, on=\"key\", how=\"outer\")\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b74f56",
   "metadata": {},
   "source": [
    "## UNION\n",
    "\n",
    "在pandas中可以透過`concat()`來模擬SQL的`UNION ALL`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "064654eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    {\"city\": [\"Chicago\", \"San Francisco\", \"New York City\"], \"rank\": range(1, 4)}\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\"city\": [\"Chicago\", \"Boston\", \"Los Angeles\"], \"rank\": [1, 4, 5]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b96150",
   "metadata": {},
   "source": [
    "```sql\n",
    "SELECT city, rank\n",
    "FROM df1\n",
    "UNION ALL\n",
    "SELECT city, rank\n",
    "FROM df2;\n",
    "/*\n",
    "         city  rank\n",
    "      Chicago     1\n",
    "San Francisco     2\n",
    "New York City     3\n",
    "      Chicago     1\n",
    "       Boston     4\n",
    "  Los Angeles     5\n",
    "*/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c513f482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            city  rank\n",
      "0        Chicago     1\n",
      "1  San Francisco     2\n",
      "2  New York City     3\n",
      "0        Chicago     1\n",
      "1         Boston     4\n",
      "2    Los Angeles     5\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "results = pd.concat([df1, df2])\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cc51a",
   "metadata": {},
   "source": [
    "SQL的`UNION`與`UNION ALL`類似，但是`UNION`會刪除重複的行。\n",
    "\n",
    "```sql\n",
    "SELECT city, rank\n",
    "FROM df1\n",
    "UNION\n",
    "SELECT city, rank\n",
    "FROM df2;\n",
    "-- notice that there is only one Chicago record this time\n",
    "/*\n",
    "         city  rank\n",
    "      Chicago     1\n",
    "San Francisco     2\n",
    "New York City     3\n",
    "       Boston     4\n",
    "  Los Angeles     5\n",
    "*/\n",
    "```\n",
    "\n",
    "在pandas中，可以將`concat()`與`drop_duplicates()`結合使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eabbfabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            city  rank\n",
      "0        Chicago     1\n",
      "1  San Francisco     2\n",
      "2  New York City     3\n",
      "1         Boston     4\n",
      "2    Los Angeles     5\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "results = pd.concat([df1, df2]).drop_duplicates()\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da028c0",
   "metadata": {},
   "source": [
    "## TOP n ROWS with OFFSET\n",
    "\n",
    "```sql\n",
    "-- MySQL\n",
    "SELECT * FROM tips\n",
    "ORDER BY tip DESC\n",
    "LIMIT 10 OFFSET 5;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3da1497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     total_bill   tip     sex smoker   day    time  size\n",
      "183       23.17  6.50    Male    Yes   Sun  Dinner     4\n",
      "214       28.17  6.50  Female    Yes   Sat  Dinner     3\n",
      "47        32.40  6.00    Male     No   Sun  Dinner     4\n",
      "239       29.03  5.92    Male     No   Sat  Dinner     3\n",
      "88        24.71  5.85    Male     No  Thur   Lunch     2\n",
      "181       23.33  5.65    Male    Yes   Sun  Dinner     2\n",
      "44        30.40  5.60    Male     No   Sun  Dinner     4\n",
      "52        34.81  5.20  Female     No   Sun  Dinner     4\n",
      "85        34.83  5.17  Female     No  Thur   Lunch     4\n",
      "211       25.89  5.16    Male    Yes   Sat  Dinner     4\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# nlargest()\n",
    "# Return the first n rows ordered by columns in descending order.\n",
    "results = tips.nlargest(10 + 5, columns=\"tip\").tail(10)\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a80ec",
   "metadata": {},
   "source": [
    "## UPDATE\n",
    "\n",
    "```sql\n",
    "UPDATE tips\n",
    "SET tip = tip*2\n",
    "WHERE tip < 2;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bab11da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     total_bill   tip     sex smoker   day    time  size\n",
      "0         16.99  1.01  Female     No   Sun  Dinner     2\n",
      "1         10.34  1.66    Male     No   Sun  Dinner     3\n",
      "2         21.01  3.50    Male     No   Sun  Dinner     3\n",
      "3         23.68  3.31    Male     No   Sun  Dinner     2\n",
      "4         24.59  3.61  Female     No   Sun  Dinner     4\n",
      "..          ...   ...     ...    ...   ...     ...   ...\n",
      "239       29.03  5.92    Male     No   Sat  Dinner     3\n",
      "240       27.18  2.00  Female    Yes   Sat  Dinner     2\n",
      "241       22.67  2.00    Male    Yes   Sat  Dinner     2\n",
      "242       17.82  1.75    Male     No   Sat  Dinner     2\n",
      "243       18.78  3.00  Female     No  Thur  Dinner     2\n",
      "\n",
      "[244 rows x 7 columns]\n",
      "     total_bill   tip     sex smoker   day    time  size\n",
      "0         16.99  2.02  Female     No   Sun  Dinner     2\n",
      "1         10.34  3.32    Male     No   Sun  Dinner     3\n",
      "2         21.01  3.50    Male     No   Sun  Dinner     3\n",
      "3         23.68  3.31    Male     No   Sun  Dinner     2\n",
      "4         24.59  3.61  Female     No   Sun  Dinner     4\n",
      "..          ...   ...     ...    ...   ...     ...   ...\n",
      "239       29.03  5.92    Male     No   Sat  Dinner     3\n",
      "240       27.18  2.00  Female    Yes   Sat  Dinner     2\n",
      "241       22.67  2.00    Male    Yes   Sat  Dinner     2\n",
      "242       17.82  3.50    Male     No   Sat  Dinner     2\n",
      "243       18.78  3.00  Female     No  Thur  Dinner     2\n",
      "\n",
      "[244 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# before UPDATE\n",
    "print(tips)\n",
    "\n",
    "# UPDATE\n",
    "tips.loc[tips[\"tip\"] < 2, \"tip\"] *= 2\n",
    "\n",
    "# after UPDATE\n",
    "print(tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c27a8e0",
   "metadata": {},
   "source": [
    "## DELETE\n",
    "\n",
    "```sql\n",
    "DELETE FROM tips\n",
    "WHERE tip > 9;\n",
    "```\n",
    "\n",
    "在pandas，我們的做法是\"SELECT\"應保留的rows成為一個新的dataframe物件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43ca3a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     total_bill   tip     sex smoker   day    time  size\n",
      "183       23.17  6.50    Male    Yes   Sun  Dinner     4\n",
      "214       28.17  6.50  Female    Yes   Sat  Dinner     3\n",
      "47        32.40  6.00    Male     No   Sun  Dinner     4\n",
      "239       29.03  5.92    Male     No   Sat  Dinner     3\n",
      "88        24.71  5.85    Male     No  Thur   Lunch     2\n",
      "181       23.33  5.65    Male    Yes   Sun  Dinner     2\n",
      "44        30.40  5.60    Male     No   Sun  Dinner     4\n",
      "52        34.81  5.20  Female     No   Sun  Dinner     4\n",
      "85        34.83  5.17  Female     No  Thur   Lunch     4\n",
      "211       25.89  5.16    Male    Yes   Sat  Dinner     4\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10 entries, 183 to 211\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   total_bill  10 non-null     float64\n",
      " 1   tip         10 non-null     float64\n",
      " 2   sex         10 non-null     object \n",
      " 3   smoker      10 non-null     object \n",
      " 4   day         10 non-null     object \n",
      " 5   time        10 non-null     object \n",
      " 6   size        10 non-null     int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 640.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tips = tips.loc[tips[\"tip\"] <= 9]\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(results.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02085d4c",
   "metadata": {},
   "source": [
    "# 數據導入與轉出 (Imports and Exports)\n",
    "\n",
    "> * 導入JSON數據\n",
    "> * 展平嵌套集合的數據\n",
    "> * 從某個網站下載CSV\n",
    "> * 讀取和寫出Excel工作表\n",
    "\n",
    "數據集(Dataset)有多種文件格式：逗號分隔值(CSV)，TAB字符分隔值(TSV)，Excel工作表(XLSX)等。某些數據格式(例如JavaScript Object Notation - JSON)並不以表格格式來存儲數據。而是將相關數據的集合嵌套在鍵值存儲中。比較下面的兩個範例：第一個範例將數據存儲在表中，第二個範例將相同的數據存儲在Python字典中。 Python的字典是鍵值數據結構的完美範例。\n",
    "\n",
    "![](images/12_01.png)\n",
    "\n",
    "具有相同數據的Python字典(dict)物件:\n",
    "\n",
    "```python\n",
    "{\n",
    "    2000: [\n",
    "        {\n",
    "            \"Award\": \"Best Actor\",\n",
    "            \"Winner\": \"Russell Crowe\"\n",
    "        },\n",
    "        {\n",
    "            \"Award\": \"Best Actress\",\n",
    "            \"Winner\": \"Julia Roberts\"\n",
    "        }\n",
    "    ],\n",
    "    2001: [\n",
    "        {\n",
    "            \"Award\": \"Best Actor\",\n",
    "            \"Winner\": \"Denzel Washington\"\n",
    "        },\n",
    "        {\n",
    "            \"Award\": \"Best Actress\",\n",
    "            \"Winner\": \"Halle Berry\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c03413",
   "metadata": {},
   "source": [
    "Pandas附帶有實用的utility函式，可將以`鍵值`格式存儲的數據處理成`表格`形式，反之亦然。很多時候，`數據導入`是數據分析中最具挑戰性的部分。一旦將數據保存在`DataFrame`中，就可以對其應用所有Pandas己經內置的數據處理函式來進行數據的運算與轉置。但是，要將數據轉換成為正確的格式與形狀可能有許多的挑戰。\n",
    "\n",
    "在教程中，我們還將學習如何使用Pandas將數據結構導出為各種文件類型和數據結構。讓我們以當今最流行的數據存儲格式之一JSON開始。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87853a6",
   "metadata": {},
   "source": [
    "##  讀取和寫入JSON文件\n",
    "\n",
    "JavaScript Object Notation (JSON)是一種用於存儲和傳輸文字(文本)數據的格式。儘管其語法受JavaScript程式語言的啟發，但`JSON`本身與語言無關。如今，包括Python在內的大多數語言都可以生成和解析`JSON`。\n",
    "\n",
    "JSON由`鍵值對`組成，其中`鍵`用作`值`的唯一標識符。冒號（：）將鍵連接到值。`鍵`必須是`字符串`。`值`可以是任何`有效的數據類型`，包括strings，numbers，boolean等。 JSON與Python的`字典對象 (dict)`相似。\n",
    "\n",
    "JSON是許多現代API常用的響應格式。來自API的原始JSON響應看起來像一個純字符串。\n",
    "\n",
    "```json\n",
    "{\"name\":\"Harry Potter\",\"age\":17,\"wizard\":true}\n",
    "```\n",
    "\n",
    "透過一些pretty print的工具來讓JSON數據容易閱讀:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"name\": \"Harry Potter\",\n",
    "    \"age\": 17,\n",
    "    \"wizard\": true,\n",
    "}\n",
    "```\n",
    "\n",
    "JSON數據包含三個鍵值對(key-value pairs)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016fdaee",
   "metadata": {},
   "source": [
    "鍵值也可以指向一個陣列，即相當於Python的list物件。見下一個JSON範例中的`friends`鍵映射到具有兩個字串的list物件。\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"name\": \"Harry Potter\",\n",
    "   \"age\": 17,\n",
    "   \"wizard\": true,\n",
    "   \"friends\": [\"Ron Weasley\", \"Hermione Granger\"],\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bfe81",
   "metadata": {},
   "source": [
    "JSON可以在嵌套物件（例如下面的`address`）中存儲其他鍵/值對。可以將其視為嵌套在另一個字典中的字典。\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"name\": \"Harry Potter\",\n",
    "   \"age\": 17,\n",
    "   \"wizard\": true,\n",
    "   \"friends\": [\"Ron Weasley\", \"Hermione Granger\"],\n",
    "   \"address\": {\n",
    "       \"street\": \"4 Privet Drive\",\n",
    "       \"town\": \"Little Whinging\"\n",
    "   }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408f967",
   "metadata": {},
   "source": [
    "### 將JSON文件加載到DataFrame中\n",
    "\n",
    "我們可以將JSON存儲在檔案擴展名為.json的純文本文件中。\n",
    "\n",
    "範例數據: `prizes.json`檔案是來自諾貝爾獎API的JSON響應。它包含一個可追溯到1901年的諾貝爾獎獲得者列表。\n",
    "\n",
    "API: http://api.nobelprize.org/v1/prize.json\n",
    "\n",
    "以下是這個JSON檔案的預覽：\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"prizes\": [\n",
    "    {\n",
    "      \"year\": \"2019\",\n",
    "      \"category\": \"chemistry\",\n",
    "      \"laureates\": [\n",
    "        {\n",
    "          \"id\": \"976\",\n",
    "          \"firstname\": \"John\",\n",
    "          \"surname\": \"Goodenough\",\n",
    "          \"motivation\": \"\\\"for the development of lithium-ion batteries\\\"\",\n",
    "          \"share\": \"3\"\n",
    "        },\n",
    "        {\n",
    "          \"id\": \"977\",\n",
    "          \"firstname\": \"M. Stanley\",\n",
    "          \"surname\": \"Whittingham\",\n",
    "          \"motivation\": \"\\\"for the development of lithium-ion batteries\\\"\",\n",
    "          \"share\": \"3\"\n",
    "        },\n",
    "        {\n",
    "          \"id\": \"978\",\n",
    "          \"firstname\": \"Akira\",\n",
    "          \"surname\": \"Yoshino\",\n",
    "          \"motivation\": \"\\\"for the development of lithium-ion batteries\\\"\",\n",
    "          \"share\": \"3\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    ...\n",
    "    ...\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea6d87",
   "metadata": {},
   "source": [
    "#### 數據結構解析\n",
    "\n",
    "這個JSON數據包括了一個level#1的鍵`prizes`映射到一個物件的列表:\n",
    "\n",
    "![](images/12_03.png)\n",
    "\n",
    "每一個在`prizes`的物件也是一個dict物件, 包括了以下的鍵值對(key-value pairs):\n",
    "* year - 年份\n",
    "* category - 類別\n",
    "* laureates - 得獎人\n",
    "\n",
    "![](images/12_04.png)\n",
    "\n",
    "由於同一個諾貝爾獎可能由多個人一同取得, 因此`laureates`的值也是一個物件的列表:\n",
    "* id - 內部編號\n",
    "* firstname - 名\n",
    "* surname - 姓\n",
    "* motivation - 動機\n",
    "* share - 多少人共享這個奨項\n",
    "\n",
    "![](images/12_05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522068f",
   "metadata": {},
   "source": [
    "Pandas的數據導入函數具有相似的命名模版。它們由`read_前綴`及其後的`文件類型`組成。例如，之前範例多次使用到`read_csv()`函數。要導入JSON文件，我們將使用`read_json()`函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12fe41d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 646 entries, 0 to 645\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   prizes  646 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 5.2+ KB\n",
      "None\n",
      "                                              prizes\n",
      "0  {'year': '2019', 'category': 'chemistry', 'lau...\n",
      "1  {'year': '2019', 'category': 'economics', 'lau...\n",
      "2  {'year': '2019', 'category': 'literature', 'la...\n",
      "3  {'year': '2019', 'category': 'peace', 'laureat...\n",
      "4  {'year': '2019', 'category': 'physics', 'overa...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nobel = pd.read_json('data/nobel.json')\n",
    "\n",
    "print(nobel.info())\n",
    "\n",
    "print(nobel.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844dfbd",
   "metadata": {},
   "source": [
    "我們已經成功地將文件導入成為`dataframe`物件了，但是這種格式對於分析來說並不理想。 Pandas識別了JSON中的top-level的鍵值`prizes`，並將其設置為列名。並把每個鍵映射的值創建成Python的dict物件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c05b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['year', 'category', 'laureates'])\n"
     ]
    }
   ],
   "source": [
    "# 從 dataframe 中取出第一筆\n",
    "first_obj = nobel.loc[0, \"prizes\"]\n",
    "\n",
    "# 檢查物件的類型\n",
    "print(type(first_obj))\n",
    "\n",
    "# 打印 dict 物件的 keys\n",
    "print(first_obj.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a9626d",
   "metadata": {},
   "source": [
    "為了有效地使用這個數據，我們需要提取top-level的鍵值對(`year`, `category`)成為`DataFrame`獨立的列。此外，我們需要讀取獲獎者(`laureates`)列表中的每個dict物件典並提取嵌套在內的一些資訊。我們的目標是為每個諾貝爾獎獲得者有個自的row，並與他們的年份`year`和類別`category`聯繫起來。理想的DataFrame形狀如下所示：\n",
    "\n",
    "idx|id           | firstname  | surname | motivation | share | year | category\n",
    "---|:-----------:|:-----------|:--------|:-----------|------:|:----:|:---------:\n",
    "0    | 976 |  John |    Goodenough   | for the develop... | 3 | 2019 | chemistry\n",
    "1    | 977 |  M. Stanley |    Whittingham     | for the develop... | 3 | 2019 | chemistry\n",
    "2    | 978 |  Akira       |    Yoshino     | for the develop... | 3 | 2019 | chemistry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8335fc",
   "metadata": {},
   "source": [
    "將嵌套的數據記錄提取到單個一維列表中被稱為展平(flattening)或正規化(normalizing)。 pandas包含一個內置的`json_normalize()`函數來處理繁雜的工作。讓我們在Nobel DataFrame的範例中進行嘗試。我們將使用loc訪問器訪問第一行的字典並將其分配給`chemistry_2019`變量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89182a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "\n",
      "一般的打印:\n",
      "{'year': '2019', 'category': 'chemistry', 'laureates': [{'id': '976', 'firstname': 'John', 'surname': 'Goodenough', 'motivation': '\"for the development of lithium-ion batteries\"', 'share': '3'}, {'id': '977', 'firstname': 'M. Stanley', 'surname': 'Whittingham', 'motivation': '\"for the development of lithium-ion batteries\"', 'share': '3'}, {'id': '978', 'firstname': 'Akira', 'surname': 'Yoshino', 'motivation': '\"for the development of lithium-ion batteries\"', 'share': '3'}]}\n",
      "\n",
      "美化後的打印:\n",
      "{'category': 'chemistry',\n",
      " 'laureates': [{'firstname': 'John',\n",
      "                'id': '976',\n",
      "                'motivation': '\"for the development of lithium-ion batteries\"',\n",
      "                'share': '3',\n",
      "                'surname': 'Goodenough'},\n",
      "               {'firstname': 'M. Stanley',\n",
      "                'id': '977',\n",
      "                'motivation': '\"for the development of lithium-ion batteries\"',\n",
      "                'share': '3',\n",
      "                'surname': 'Whittingham'},\n",
      "               {'firstname': 'Akira',\n",
      "                'id': '978',\n",
      "                'motivation': '\"for the development of lithium-ion batteries\"',\n",
      "                'share': '3',\n",
      "                'surname': 'Yoshino'}],\n",
      " 'year': '2019'}\n"
     ]
    }
   ],
   "source": [
    "# 取得某一個column中的特定cell\n",
    "chemistry_2019 = nobel.loc[0, \"prizes\"]\n",
    "\n",
    "print(type(chemistry_2019))\n",
    "\n",
    "print(\"\")\n",
    "print(\"一般的打印:\")\n",
    "print(chemistry_2019)\n",
    "\n",
    "# 引入pprint的套件來幫助打印 human readable的格式\n",
    "import pprint\n",
    "\n",
    "print(\"\")\n",
    "print(\"美化後的打印:\")\n",
    "pprint.pprint(chemistry_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb508c9",
   "metadata": {},
   "source": [
    "讓我們將`chemistry_2019`字典物件傳遞給`json_normalize`函數的`data`參數。 Pandas會提取三個top-level的字典鍵(\"`year`\", \"`category`\"與\"`laureates`\")來成為DataFrame中的列。不幸的是，該函式庫沒有將獲獎者`laureates`列表中的嵌套dict物件也轉換成單獨的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "785d2f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   year       1 non-null      object\n",
      " 1   category   1 non-null      object\n",
      " 2   laureates  1 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 152.0+ bytes\n",
      "None\n",
      "   year   category                                          laureates\n",
      "0  2019  chemistry  [{'id': '976', 'firstname': 'John', 'surname':...\n"
     ]
    }
   ],
   "source": [
    "df_tmp = pd.json_normalize(data = chemistry_2019)\n",
    "\n",
    "print(df_tmp.info())\n",
    "\n",
    "print(df_tmp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb2f93",
   "metadata": {},
   "source": [
    "我們可以利用`record_path`參數來正規化嵌套的`獲獎者laureates`。我們給予一個字串，該字串指示字典dict中的哪個`鍵`包含嵌套記錄。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be21e08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          3 non-null      object\n",
      " 1   firstname   3 non-null      object\n",
      " 2   surname     3 non-null      object\n",
      " 3   motivation  3 non-null      object\n",
      " 4   share       3 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 248.0+ bytes\n",
      "None\n",
      "    id   firstname      surname  \\\n",
      "0  976        John   Goodenough   \n",
      "1  977  M. Stanley  Whittingham   \n",
      "2  978       Akira      Yoshino   \n",
      "\n",
      "                                       motivation share  \n",
      "0  \"for the development of lithium-ion batteries\"     3  \n",
      "1  \"for the development of lithium-ion batteries\"     3  \n",
      "2  \"for the development of lithium-ion batteries\"     3  \n"
     ]
    }
   ],
   "source": [
    "df_tmp = pd.json_normalize(data = chemistry_2019, record_path= 'laureates')\n",
    "\n",
    "print(df_tmp.info())\n",
    "\n",
    "print(df_tmp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ace3f6",
   "metadata": {},
   "source": [
    "現在Dataframe裡頭有我們想要的嵌套`獲獎者laureates`的一些欄位資訊了，但是現在我們也失去了原始的`year`與`categroy`列。為了保留這些top-level的鍵值對，我們可以將帶有其名稱的列表傳遞給`meta`參數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f752f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          3 non-null      object\n",
      " 1   firstname   3 non-null      object\n",
      " 2   surname     3 non-null      object\n",
      " 3   motivation  3 non-null      object\n",
      " 4   share       3 non-null      object\n",
      " 5   year        3 non-null      object\n",
      " 6   category    3 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 296.0+ bytes\n",
      "None\n",
      "    id   firstname      surname  \\\n",
      "0  976        John   Goodenough   \n",
      "1  977  M. Stanley  Whittingham   \n",
      "2  978       Akira      Yoshino   \n",
      "\n",
      "                                       motivation share  year   category  \n",
      "0  \"for the development of lithium-ion batteries\"     3  2019  chemistry  \n",
      "1  \"for the development of lithium-ion batteries\"     3  2019  chemistry  \n",
      "2  \"for the development of lithium-ion batteries\"     3  2019  chemistry  \n"
     ]
    }
   ],
   "source": [
    "df_tmp = pd.json_normalize(data=chemistry_2019, record_path=\"laureates\", meta=[\"year\", \"category\"])\n",
    "\n",
    "print(df_tmp.info())\n",
    "\n",
    "print(df_tmp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb5c18",
   "metadata": {},
   "source": [
    "我們的正規化策略(normalization strategy)已經成功地應用在單一的`prizes`字典物件。幸運的是`json_normalize`函數可以接受一個`Series`的字典物件並element-wise重複執行資料轉換提取的邏輯。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a22669ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'laureates'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-96a5406ece72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnobel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prizes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrecord_path\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"laureates\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"year\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"category\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/json/_normalize.py\u001b[0m in \u001b[0;36m_json_normalize\u001b[0;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep, max_level)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mrecords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0m_recursive_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/json/_normalize.py\u001b[0m in \u001b[0;36m_recursive_extract\u001b[0;34m(data, path, seen_meta, level)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                 \u001b[0mrecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pull_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m                 recs = [\n\u001b[1;32m    311\u001b[0m                     \u001b[0mnested_to_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/json/_normalize.py\u001b[0m in \u001b[0;36m_pull_records\u001b[0;34m(js, spec)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mnon\u001b[0m \u001b[0miterable\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pull_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# GH 31507 GH 30145, GH 26284 if result is not list, raise TypeError if not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/json/_normalize.py\u001b[0m in \u001b[0;36m_pull_field\u001b[0;34m(js, spec)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'laureates'"
     ]
    }
   ],
   "source": [
    "# nobel 是之前步驟所創構的 dataframe 物件\n",
    "\n",
    "df_tmp = pd.json_normalize(\n",
    "    data = nobel[\"prizes\"],\n",
    "    record_path= \"laureates\",\n",
    "    meta = [\"year\", \"category\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3501cd64",
   "metadata": {},
   "source": [
    "不幸的是，Pandas引發了`KeyError`異常。在`prizes`的`Series`物件中某些詞典dict物件中並沒有`laureates`的鍵。`json_normalize`函數無法從不存在的列表中提取嵌套的獲獎者信息。\n",
    "\n",
    "這種問題的一種解決方法是找出這些缺少`laureates`的記錄，然後手動將一個空列表的值分配給它們。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d2257",
   "metadata": {},
   "source": [
    "讓我們花點時間回顧一下Python字典上的setdefault方法。考慮下面的字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e60c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheese_consumption = {\n",
    "    \"France\": 57.9,\n",
    "    \"Germany\": 53.2,\n",
    "    \"Luxembourg\": 53.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1784836e",
   "metadata": {},
   "source": [
    "`setdefault`方法將鍵值對設定在字典(dict)物件上。如果`鍵`確實存在，則該方法返回其現有值。\n",
    "\n",
    "下面的範例嘗試將鍵`France`添加到值為`100`的`cheese_consumption`字典物件中。由於該鍵已存在，因此沒有任何更改。 Python保留原始值57.9。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c33cec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.9\n"
     ]
    }
   ],
   "source": [
    "cheese_consumption.setdefault(\"France\", 100)\n",
    "\n",
    "print(cheese_consumption[\"France\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4347095",
   "metadata": {},
   "source": [
    "相比之下，下一個範例使用參數`Italy`調用`setdefault`。字典中不存在鍵`Italy`，因此Python對其進行了添加並將其賦值為48。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f11a9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "{'France': 57.9, 'Germany': 53.2, 'Luxembourg': 53.2, 'Italy': 48}\n"
     ]
    }
   ],
   "source": [
    "cheese_consumption.setdefault(\"Italy\", 48)\n",
    "\n",
    "print(cheese_consumption[\"Italy\"])\n",
    "\n",
    "print(cheese_consumption)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f59b0",
   "metadata": {},
   "source": [
    "讓我們將此技巧應用於`prizes`中的每個嵌套字典物件。如果字典沒有`prizes`鍵，我們將使用`setdefault`方法將其添加為空列表。我們要應用`apply`方法在每個Series元素上單獨進行迭代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d528bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      {'year': '2019', 'category': 'chemistry', 'lau...\n",
      "1      {'year': '2019', 'category': 'economics', 'lau...\n",
      "2      {'year': '2019', 'category': 'literature', 'la...\n",
      "3      {'year': '2019', 'category': 'peace', 'laureat...\n",
      "4      {'year': '2019', 'category': 'physics', 'overa...\n",
      "                             ...                        \n",
      "641    {'year': '1901', 'category': 'chemistry', 'lau...\n",
      "642    {'year': '1901', 'category': 'literature', 'la...\n",
      "643    {'year': '1901', 'category': 'peace', 'laureat...\n",
      "644    {'year': '1901', 'category': 'physics', 'laure...\n",
      "645    {'year': '1901', 'category': 'medicine', 'laur...\n",
      "Name: prizes, Length: 646, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 定義一個function來對應用到每一個元素\n",
    "def add_laureates_key(entry):\n",
    "    entry.setdefault(\"laureates\", [])\n",
    "    \n",
    "# 缺失值的處理\n",
    "nobel[\"prizes\"].apply(add_laureates_key)\n",
    "\n",
    "print(nobel[\"prizes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5feed",
   "metadata": {},
   "source": [
    "現在，所有嵌套詞典都有一個`laurates`鍵，我們可以重新調用`json_normalize`函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88ad9baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 950 entries, 0 to 949\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          950 non-null    object\n",
      " 1   firstname   950 non-null    object\n",
      " 2   surname     921 non-null    object\n",
      " 3   motivation  950 non-null    object\n",
      " 4   share       950 non-null    object\n",
      " 5   year        950 non-null    object\n",
      " 6   category    950 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 52.1+ KB\n",
      "None\n",
      "    id   firstname      surname  \\\n",
      "0  976        John   Goodenough   \n",
      "1  977  M. Stanley  Whittingham   \n",
      "2  978       Akira      Yoshino   \n",
      "3  982     Abhijit     Banerjee   \n",
      "4  983      Esther        Duflo   \n",
      "\n",
      "                                          motivation share  year   category  \n",
      "0     \"for the development of lithium-ion batteries\"     3  2019  chemistry  \n",
      "1     \"for the development of lithium-ion batteries\"     3  2019  chemistry  \n",
      "2     \"for the development of lithium-ion batteries\"     3  2019  chemistry  \n",
      "3  \"for their experimental approach to alleviatin...     3  2019  economics  \n",
      "4  \"for their experimental approach to alleviatin...     3  2019  economics  \n"
     ]
    }
   ],
   "source": [
    "winners = pd.json_normalize(\n",
    "             data = nobel[\"prizes\"],\n",
    "             record_path = \"laureates\",\n",
    "             meta = [\"year\", \"category\"]\n",
    "         )\n",
    "\n",
    "print(winners.info())\n",
    "\n",
    "print(winners.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33fec2",
   "metadata": {},
   "source": [
    "終於完成了！嵌套的數據已被正規化並轉換成二維表結構中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d4cfa9",
   "metadata": {},
   "source": [
    "### 將DataFrame導出成JSON檔案文件\n",
    "\n",
    "現在讓我們嘗試相反的過程：將DataFrame轉換為JSON表示並將其導出成JSON文件檔案。 `to_json`方法從pandas數據結構創建`JSON`字串。它的`orient`參數定義pandas返回數據的格式。下一個範例使用參數`records`返回鍵值對象的JSON陣列。 Pandas將列名稱存儲為字典`鍵`，指向該行的相應值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "296e1d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id   firstname      surname  \\\n",
      "0  976        John   Goodenough   \n",
      "1  977  M. Stanley  Whittingham   \n",
      "\n",
      "                                       motivation share  year   category  \n",
      "0  \"for the development of lithium-ion batteries\"     3  2019  chemistry  \n",
      "1  \"for the development of lithium-ion batteries\"     3  2019  chemistry  \n",
      "[\n",
      "  {\n",
      "    \"id\": \"976\",\n",
      "    \"firstname\": \"John\",\n",
      "    \"surname\": \"Goodenough\",\n",
      "    \"motivation\": \"\\\"for the development of lithium-ion batteries\\\"\",\n",
      "    \"share\": \"3\",\n",
      "    \"year\": \"2019\",\n",
      "    \"category\": \"chemistry\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"977\",\n",
      "    \"firstname\": \"M. Stanley\",\n",
      "    \"surname\": \"Whittingham\",\n",
      "    \"motivation\": \"\\\"for the development of lithium-ion batteries\\\"\",\n",
      "    \"share\": \"3\",\n",
      "    \"year\": \"2019\",\n",
      "    \"category\": \"chemistry\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(winners.head(2))\n",
    "\n",
    "winners_json = winners.head(2).to_json(orient='records')\n",
    "\n",
    "# 引入 json 模組來解析json字串並打印出來\n",
    "import json\n",
    "\n",
    "print(json.dumps(json.loads(winners_json), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d7e5e6",
   "metadata": {},
   "source": [
    "pandas的`to_json()`方法中的參數`orient`包含了幾種Dataframe轉成JSON格式的選項:\n",
    "* `split` : dict like {‘index’ -> [index], ‘columns’ -> [columns], ‘data’ -> [values]}\n",
    "* records\n",
    "* index\n",
    "* columns\n",
    "* values\n",
    "* table\n",
    "\n",
    "\n",
    "參考: [pandas.DataFrame.to_json](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed103434",
   "metadata": {},
   "source": [
    "JSON格式符合你的期望後，將JSON文件名作為第一個參數傳遞給`to_json`方法。Pandas會將JSON字串寫入與Jupyter Notebook相同目錄中的JSON文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2d45751",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners.to_json(\"winners.json\", orient = \"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af995f",
   "metadata": {},
   "source": [
    "## 讀取和寫入CSV文件\n",
    "\n",
    "我們的下一個數據集是美國紐約市的嬰兒名字的集合。每筆資料包括姓名`name`，出生年月`birth year`，性別`gender`，種族`ethnicity`，人數`count`和受歡迎程度`popularity rank`。 CSV文件託管在紐約市政府網站上，並位於 https://data.cityofnewyork.us/api/views/25th-nujf/rows.csv。\n",
    "\n",
    "### 將CSV文件加載到DataFrame中\n",
    "\n",
    "我們可以在Web瀏覽器中訪問該網站，並將數據集下載到我們的計算機上以進行本地存儲(data/Popular_Baby_Names.csv)。或者，我們也可以將URL作為第一個參數直接傳遞給read_csv函數。Pandas將從網站上獲取數據集。當託管數據頻繁更改時，透過URL來取得更新的數據會很有幫助。它為我們節省了下載數據集的手動工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a04af86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29464 entries, 0 to 29463\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Year of Birth       29464 non-null  int64 \n",
      " 1   Gender              29464 non-null  object\n",
      " 2   Ethnicity           29464 non-null  object\n",
      " 3   Child's First Name  29464 non-null  object\n",
      " 4   Count               29464 non-null  int64 \n",
      " 5   Rank                29464 non-null  int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "   Year of Birth  Gender Ethnicity Child's First Name  Count  Rank\n",
      "0           2011  FEMALE  HISPANIC          GERALDINE     13    75\n",
      "1           2011  FEMALE  HISPANIC                GIA     21    67\n",
      "2           2011  FEMALE  HISPANIC             GIANNA     49    42\n",
      "3           2011  FEMALE  HISPANIC            GISELLE     38    51\n",
      "4           2011  FEMALE  HISPANIC              GRACE     36    53\n"
     ]
    }
   ],
   "source": [
    "baby_names = pd.read_csv('data/Popular_Baby_Names.csv')\n",
    "\n",
    "print(baby_names.info())\n",
    "\n",
    "print(baby_names.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa3ff7",
   "metadata": {},
   "source": [
    "### 將DataFrame導出成CSV檔案文件\n",
    "\n",
    "讓我們嘗試使用`to_csv()`方法將baby_names的dataframe物件導出成為CSV文件。若不帶參數的情況下，該方法將直接在Jupyter Notebook中輸出CSV字串。遵循CSV約定，pandas用`逗號`分隔行值，並使用換行符分隔不同的行。提醒一下，`\\n`字符表示Python中的換行符。以下是該方法輸出的一個資料預覽。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f1da1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",Year of Birth,Gender,Ethnicity,Child's First Name,Count,Rank\n",
      "0,2011,FEMALE,HISPANIC,GERALDINE,13,75\n",
      "1,2011,FEMALE,HISPANIC,GIA,21,67\n",
      "2,2011,FEMALE,HISPANIC,GIANNA,49,42\n",
      "3,2011,FEMALE,HISPANIC,GISELLE,38,51\n",
      "4,2011,FEMALE,HISPANIC,GRACE,36,53\n",
      "5,2011,FEMALE,HISPANIC,GUADALUPE,26,62\n",
      "6,2011,FEMALE,HISPANIC,HAILEY,126,8\n",
      "7,2011,FEMALE,HISPANIC,HALEY,14,74\n",
      "8,2011,FEMALE,HISPANIC,HANNAH,17,71\n",
      "9,2011,FEMALE,HISPANIC,HAYLEE,17,71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_csv = baby_names.head(10).to_csv()\n",
    "\n",
    "print(result_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be35e4ba",
   "metadata": {},
   "source": [
    "注意字符串開頭的逗號和每個`\\n`符號後面的數值（0、1、2等）。預設情況下，pandas在CSV字符串中包含DataFrame`索引`列。我們可以通過將`index`參數傳遞為`False`來排除索引列的導出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5c8b1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year of Birth,Gender,Ethnicity,Child's First Name,Count,Rank\n",
      "2011,FEMALE,HISPANIC,GERALDINE,13,75\n",
      "2011,FEMALE,HISPANIC,GIA,21,67\n",
      "2011,FEMALE,HISPANIC,GIANNA,49,42\n",
      "2011,FEMALE,HISPANIC,GISELLE,38,51\n",
      "2011,FEMALE,HISPANIC,GRACE,36,53\n",
      "2011,FEMALE,HISPANIC,GUADALUPE,26,62\n",
      "2011,FEMALE,HISPANIC,HAILEY,126,8\n",
      "2011,FEMALE,HISPANIC,HALEY,14,74\n",
      "2011,FEMALE,HISPANIC,HANNAH,17,71\n",
      "2011,FEMALE,HISPANIC,HAYLEE,17,71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_csv = baby_names.head(10).to_csv(index=False)\n",
    "\n",
    "print(result_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3703de",
   "metadata": {},
   "source": [
    "要將字符串寫入CSV文件，請將其文件名作為第一個參數傳遞給該方法。確保包括.csv擴展名。如果我們不提供特定的路徑，Pandas會將文件寫入Jupyter Notebook所在的目錄。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc2bb009",
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names.to_csv('nyc_baby_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be47bbc3",
   "metadata": {},
   "source": [
    "該方法在Notebook單元下方不會產生任何輸出。但是，如果我們回到Jupyter Notebook導航界面，則可以看到Pandas已經創建了CSV文件檔案了。\n",
    "\n",
    "預設情況下，pandas將所有DataFrame列寫入CSV文件。我們可以通過將列名稱的子集傳遞給columns參數來限制列的導出。下一個範例生成僅包含 Gender, Child's First Name及Count列的CSV。請注意，執行Jupyter Notebook單元會覆蓋目錄中現有的`nyc_baby_names.csv`文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba4a5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names.to_csv('nyc_baby_names.csv',\n",
    "                 index=False,\n",
    "                 columns=[\"Gender\", \"Child's First Name\", \"Count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f24eef3",
   "metadata": {},
   "source": [
    "如果文字檔是使用 `\\t` (TAB)來做為欄位的分隔字符的資料檔(TSV), 只要`read_csv()`或`write_csv()`指定`sep='\\t'`就可以處理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c4e59d",
   "metadata": {},
   "source": [
    "## 讀取和寫入Excel工作簿"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd56014",
   "metadata": {},
   "source": [
    "Excel是當今使用最廣泛的電子表格應用程序。通過Pandas，可以輕鬆地讀取和寫入Excel工作簿，甚至特定的工作表。\n",
    "\n",
    "Pandas需要`xlrd`和`openpyxl`套件才能與Excel交互。這些套件是將Python連接到Excel的粘合劑。\n",
    "\n",
    "參考: https://pypi.org/project/xlrd/\n",
    "\n",
    "參考: https://pypi.org/project/openpyxl/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98b33c",
   "metadata": {},
   "source": [
    "### 將XLSX文件加載到DataFrame中\n",
    "\n",
    "Pandas的`read_excel()`函數將Excel工作簿導入到DataFrame中。它的第一個參數`io`接受帶有工作簿路徑的字符串。確保在文件名中包含`xlsx`擴展名。預設情況下，panbdas僅導入工作簿中的第一個工作表。\n",
    "\n",
    "範例資料檔 `Single Worksheet.xlsx` Excel工作簿是一個不錯的起點。它僅包含一個`Data`工作表。\n",
    "\n",
    "![](images/12_06.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a9a3752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   First Name  5 non-null      object\n",
      " 1   Last Name   5 non-null      object\n",
      " 2   City        5 non-null      object\n",
      " 3   Gender      5 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 288.0+ bytes\n",
      "None\n",
      "  First Name Last Name           City Gender\n",
      "0    Brandon     James          Miami      M\n",
      "1       Sean   Hawkins         Denver      M\n",
      "2       Judy       Day    Los Angeles      F\n",
      "3     Ashley      Ruiz  San Francisco      F\n",
      "4  Stephanie     Gomez       Portland      F\n"
     ]
    }
   ],
   "source": [
    "df_xlsx = pd.read_excel('data/Single Worksheet.xlsx')\n",
    "\n",
    "print(df_xlsx.info())\n",
    "\n",
    "print(df_xlsx.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37affd",
   "metadata": {},
   "source": [
    "`read_excel()`函數支持許多與`read_csv()`相同的參數，包括用於設置索引列的`index_col`，用於選擇列的`usecols`以及用於將單列工作表強制轉換為`Series`對象的`usecols`。在下一個範例中，我們將**City**列設置為索引，並僅保留數據集的4列中的3列。注意，如果我們為index_col參數提供一列，則還必須將該列包括在usecols列表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7acffa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5 entries, Miami to Portland\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   First Name  5 non-null      object\n",
      " 1   Last Name   5 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 120.0+ bytes\n",
      "None\n",
      "              First Name Last Name\n",
      "City                              \n",
      "Miami            Brandon     James\n",
      "Denver              Sean   Hawkins\n",
      "Los Angeles         Judy       Day\n",
      "San Francisco     Ashley      Ruiz\n",
      "Portland       Stephanie     Gomez\n"
     ]
    }
   ],
   "source": [
    "df_xlsx = pd.read_excel(io='data/Single Worksheet.xlsx',\n",
    "                       usecols=[\"City\", \"First Name\", \"Last Name\"],\n",
    "                       index_col=\"City\")\n",
    "\n",
    "print(df_xlsx.info())\n",
    "\n",
    "print(df_xlsx.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20367dc1",
   "metadata": {},
   "source": [
    "當一個工作簿包含多個工作表時，複雜度會稍微增加。 `Multiple Worksheets.xlsx`文件包含三個工作表：Data1，Data2和Data3。預設情況下，pandas僅導入工作簿中的第一個工作表。\n",
    "\n",
    "![](images/12_07.png)\n",
    "\n",
    "![](images/12_08.png)\n",
    "\n",
    "![](images/12_09.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d146517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   First Name  5 non-null      object\n",
      " 1   Last Name   5 non-null      object\n",
      " 2   City        5 non-null      object\n",
      " 3   Gender      5 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 288.0+ bytes\n",
      "None\n",
      "  First Name Last Name           City Gender\n",
      "0    Brandon     James          Miami      M\n",
      "1       Sean   Hawkins         Denver      M\n",
      "2       Judy       Day    Los Angeles      F\n",
      "3     Ashley      Ruiz  San Francisco      F\n",
      "4  Stephanie     Gomez       Portland      F\n"
     ]
    }
   ],
   "source": [
    "df_xlsx = pd.read_excel(\"data/Multiple Worksheets.xlsx\")\n",
    "\n",
    "print(df_xlsx.info())\n",
    "\n",
    "print(df_xlsx.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb80b0",
   "metadata": {},
   "source": [
    "Pandas為每個工作表分配一個從0開始的索引。要導入特定的工作表，我們可以將`sheet_name`參數傳遞給工作表的索引位置或其名稱。預設參數為`0`（第一個工作表）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efae4f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   First Name  5 non-null      object\n",
      " 1   Last Name   5 non-null      object\n",
      " 2   City        5 non-null      object\n",
      " 3   Gender      5 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 288.0+ bytes\n",
      "None\n",
      "  First Name Last Name           City Gender\n",
      "0    Brandon     James          Miami      M\n",
      "1       Sean   Hawkins         Denver      M\n",
      "2       Judy       Day    Los Angeles      F\n",
      "3     Ashley      Ruiz  San Francisco      F\n",
      "4  Stephanie     Gomez       Portland      F\n"
     ]
    }
   ],
   "source": [
    "df_xlsx = pd.read_excel(\"data/Multiple Worksheets.xlsx\", sheet_name=0)\n",
    "\n",
    "df_xlsx = pd.read_excel(\"data/Multiple Worksheets.xlsx\", sheet_name='Data 1')\n",
    "\n",
    "print(df_xlsx.info())\n",
    "\n",
    "print(df_xlsx.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ebc415",
   "metadata": {},
   "source": [
    "要導入所有工作表，請將參數`None`傳遞給`sheet_name`參數。 `read_excel()`函數返回一個字典dict物件，其中工作表的名稱為`鍵`，而相應的DataFrames為`值`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85504be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'Data 1':   First Name Last Name           City Gender\n",
      "0    Brandon     James          Miami      M\n",
      "1       Sean   Hawkins         Denver      M\n",
      "2       Judy       Day    Los Angeles      F\n",
      "3     Ashley      Ruiz  San Francisco      F\n",
      "4  Stephanie     Gomez       Portland      F, 'Data 2':   First Name Last Name           City Gender\n",
      "0     Parker     Power        Raleigh      F\n",
      "1    Preston  Prescott   Philadelphia      F\n",
      "2    Ronaldo   Donaldo         Bangor      M\n",
      "3      Megan   Stiller  San Francisco      M\n",
      "4     Bustin    Jieber         Austin      F, 'Data 3':   First Name  Last Name     City Gender\n",
      "0     Robert     Miller  Seattle      M\n",
      "1       Tara     Garcia  Phoenix      F\n",
      "2    Raphael  Rodriguez  Orlando      M}\n"
     ]
    }
   ],
   "source": [
    "dict_xlsx = pd.read_excel('data/Multiple Worksheets.xlsx', sheet_name=None)\n",
    "\n",
    "print(type(dict_xlsx))\n",
    "\n",
    "print(dict_xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5ef6ac",
   "metadata": {},
   "source": [
    "要訪問一個DataFrame/工作表，我們訪問字典中的一個`鍵`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50e4bdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   First Name  5 non-null      object\n",
      " 1   Last Name   5 non-null      object\n",
      " 2   City        5 non-null      object\n",
      " 3   Gender      5 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 288.0+ bytes\n",
      "None\n",
      "  First Name Last Name           City Gender\n",
      "0     Parker     Power        Raleigh      F\n",
      "1    Preston  Prescott   Philadelphia      F\n",
      "2    Ronaldo   Donaldo         Bangor      M\n",
      "3      Megan   Stiller  San Francisco      M\n",
      "4     Bustin    Jieber         Austin      F\n"
     ]
    }
   ],
   "source": [
    "df_xlsx = dict_xlsx[\"Data 2\"]\n",
    "\n",
    "print(df_xlsx.info())\n",
    "\n",
    "print(df_xlsx.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8de47",
   "metadata": {},
   "source": [
    "要限制pandas導入的工作表範圍，請將`sheet_name`參數傳遞給索引位置或工作表名稱的列表。Pandas將返回一個字典，該字典的鍵與sheet_name列表中的字符串匹配。下一個範例僅導入Data 1和Data 3工作表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0406455f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'Data 1':   First Name Last Name           City Gender\n",
      "0    Brandon     James          Miami      M\n",
      "1       Sean   Hawkins         Denver      M\n",
      "2       Judy       Day    Los Angeles      F\n",
      "3     Ashley      Ruiz  San Francisco      F\n",
      "4  Stephanie     Gomez       Portland      F, 'Data 3':   First Name  Last Name     City Gender\n",
      "0     Robert     Miller  Seattle      M\n",
      "1       Tara     Garcia  Phoenix      F\n",
      "2    Raphael  Rodriguez  Orlando      M}\n"
     ]
    }
   ],
   "source": [
    "dict_xlsx = pd.read_excel('data/Multiple Worksheets.xlsx',\n",
    "                         sheet_name=[\"Data 1\", \"Data 3\"])\n",
    "\n",
    "print(type(dict_xlsx))\n",
    "\n",
    "print(dict_xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c811bf",
   "metadata": {},
   "source": [
    "### 將DataFrame導出成XSLX檔案文件\n",
    "\n",
    "讓我們使用`baby_names`的DataFrame物件來作為Excel導出的資料集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf43289f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29464 entries, 0 to 29463\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Year of Birth       29464 non-null  int64 \n",
      " 1   Gender              29464 non-null  object\n",
      " 2   Ethnicity           29464 non-null  object\n",
      " 3   Child's First Name  29464 non-null  object\n",
      " 4   Count               29464 non-null  int64 \n",
      " 5   Rank                29464 non-null  int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "   Year of Birth  Gender Ethnicity Child's First Name  Count  Rank\n",
      "0           2011  FEMALE  HISPANIC          GERALDINE     13    75\n",
      "1           2011  FEMALE  HISPANIC                GIA     21    67\n",
      "2           2011  FEMALE  HISPANIC             GIANNA     49    42\n",
      "3           2011  FEMALE  HISPANIC            GISELLE     38    51\n",
      "4           2011  FEMALE  HISPANIC              GRACE     36    53\n"
     ]
    }
   ],
   "source": [
    "print(baby_names.info())\n",
    "\n",
    "print(baby_names.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f994ae2",
   "metadata": {},
   "source": [
    "假設我們想將數據集分為2個DataFrame，每種性別單獨一個。然後，我們想將每個DataFrame寫入到一個新的Excel工作簿中的成為單獨的工作表。\n",
    "\n",
    "我們可以從過濾baby_names的DataFrame開始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b2c6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "girls = baby_names[baby_names[\"Gender\"] == \"FEMALE\"]\n",
    "boys = baby_names[baby_names[\"Gender\"] == \"MALE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee6b99e",
   "metadata": {},
   "source": [
    "與寫入CSV相比，寫入Excel工作簿需要更多的步驟。首先，我們需要創建一個`ExcelWriter`物件。該物件是工作簿的基礎。我們將各個`工作表`附加到該物件上。\n",
    "\n",
    "`ExcelWriter`構造函數的第一個參數`path`接受帶有新工作簿文件名的字符串。如果我們不提供路徑，pandas將在與Jupyter Notebook相同的目錄中創建Excel文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e4e3214",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pd.ExcelWriter(\"baby_names.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07776ea5",
   "metadata": {},
   "source": [
    "接下來，我們需要將我們的DataFrame物件連接到工作簿中的各個工作表。 DataFrame的`to_excel()`方法的第一個參數`excel_writer`接受`ExcelWriter`物件。 `sheet_name`參數接受具有所需工作表名稱的字符串。\n",
    "\n",
    "最後，我們可以將`index`參數傳遞False值來排除DataFrame索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2cdfe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "girls.to_excel(excel_writer=excel_file,\n",
    "              sheet_name=\"Girls\",\n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceadd5d",
   "metadata": {},
   "source": [
    "請注意，此時pandas尚未創建Excel工作簿。\n",
    "\n",
    "讓我們將第二個DataFrame連接到Excel工作簿。我們在boys的DataFrame上調`to_excel()`方法，並將相同的ExcelWriter對像傳遞給excel_writer參數。現在，pandas知道應該將兩個數據集寫入同一工作簿。\n",
    "    \n",
    "我們還要將`sheet_name`參數的字符串參數更改為其他名稱。要過濾大熊貓將包括的列，請將其名稱列表傳遞給columns參數。下一個範例告訴pandas只包括Child's First Name, Count 和 Rank列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15d497e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "boys.to_excel(\n",
    "             excel_writer=excel_file,\n",
    "             sheet_name = \"Boys\",\n",
    "             index = False,\n",
    "             columns = [\"Child's First Name\", \"Count\", \"Rank\"]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354cd16",
   "metadata": {},
   "source": [
    "現在，我們已經配置了好創建Excel工作簿的相關資料，現在可以將其寫入檔案系統了。在`excel_file`的ExcelWriter物件上調用`save()`方法來完成最後的步驟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d79ee912",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7aa92",
   "metadata": {},
   "source": [
    "查看Jupyter Notebook界面；pandas在同一文件夾中創建了`baby_names.xlsx`文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362dac17",
   "metadata": {},
   "source": [
    "## 讀取和寫入Parquet文件\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb53cf",
   "metadata": {},
   "source": [
    "![](images/parquet_01_row_column.png)\n",
    "\n",
    "![](images/parquet_02_row_column.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f4c66",
   "metadata": {},
   "source": [
    "**範例數據**: `nyc_taxi_dataset.zip`檔案是`紐約市計程車和禮車協會`所發佈的一個公開資料集。\n",
    "\n",
    "資料筆數: 729,322 （73萬筆）\n",
    "資料格式: CSV\n",
    "資料大小(未壓縮): 94 MB\n",
    "資料大小(己壓縮): 32 MB\n",
    "\n",
    "資料欄位:\n",
    "* id - 車程編號\n",
    "* vendor_id - 計程車行編號\n",
    "* pickup_datetime - 上車日期時間\n",
    "* dropoff_datetime - 下車日期時間\n",
    "* passenger_count - 乘客人數\n",
    "* pickup_longitude - 上車經度\n",
    "* pickup_latitude - 上車緯度\n",
    "* dropoff_longitude - 下車經度\n",
    "* dropoff_latitude - 下車緯度\n",
    "* store_and_fwd_flag - 是否直接連線上傳b Y/N\n",
    "* trip_duration - 車程持續時間(以秒為單位)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c87ae",
   "metadata": {},
   "source": [
    "### 將CSV文件加載到DataFrame中並導出成Parquet文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f476f7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 729322 entries, 0 to 729321\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  729322 non-null  object \n",
      " 1   vendor_id           729322 non-null  int64  \n",
      " 2   pickup_datetime     729322 non-null  object \n",
      " 3   dropoff_datetime    729322 non-null  object \n",
      " 4   passenger_count     729322 non-null  int64  \n",
      " 5   pickup_longitude    729322 non-null  float64\n",
      " 6   pickup_latitude     729322 non-null  float64\n",
      " 7   dropoff_longitude   729322 non-null  float64\n",
      " 8   dropoff_latitude    729322 non-null  float64\n",
      " 9   store_and_fwd_flag  729322 non-null  object \n",
      " 10  trip_duration       729322 non-null  int64  \n",
      "dtypes: float64(4), int64(3), object(4)\n",
      "memory usage: 61.2+ MB\n",
      "None\n",
      "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
      "0  id1080784          2  2016-02-29 16:40:21  2016-02-29 16:47:01   \n",
      "1  id0889885          1  2016-03-11 23:35:37  2016-03-11 23:53:57   \n",
      "2  id0857912          2  2016-02-21 17:59:33  2016-02-21 18:26:48   \n",
      "3  id3744273          2  2016-01-05 09:44:31  2016-01-05 10:03:32   \n",
      "4  id0232939          1  2016-02-17 06:42:23  2016-02-17 06:56:31   \n",
      "\n",
      "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
      "0                1        -73.953918        40.778873         -73.963875   \n",
      "1                2        -73.988312        40.731743         -73.994751   \n",
      "2                2        -73.997314        40.721458         -73.948029   \n",
      "3                6        -73.961670        40.759720         -73.956779   \n",
      "4                1        -74.017120        40.708469         -73.988182   \n",
      "\n",
      "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
      "0         40.771164                  N            400  \n",
      "1         40.694931                  N           1100  \n",
      "2         40.774918                  N           1635  \n",
      "3         40.780628                  N           1141  \n",
      "4         40.740631                  N            848  \n",
      "(729322, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nyc_tax = pd.read_csv('data/nyc_taxi_dataset.zip')\n",
    "\n",
    "print(nyc_tax.info())\n",
    "print(nyc_tax.head())\n",
    "print(nyc_tax.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cbc026",
   "metadata": {},
   "source": [
    "使用Pandas來轉換Dataframe成為`parquet`格式並且進行壓縮。\n",
    "\n",
    "資料筆數: 729,322 （73萬筆）\n",
    "資料格式: parquet\n",
    "資料大小(未壓縮): 26 MB\n",
    "資料大小(己壓縮): 18 MB    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22680540",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_tax.to_parquet('data/nyc_taxi_trip_duration.parquet')\n",
    "\n",
    "nyc_tax.to_parquet('data/nyc_taxi_trip_duration.parquet.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9eee4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2016-02-29 16:40:21\n",
       "1         2016-03-11 23:35:37\n",
       "2         2016-02-21 17:59:33\n",
       "3         2016-01-05 09:44:31\n",
       "4         2016-02-17 06:42:23\n",
       "                 ...         \n",
       "729317    2016-05-21 13:29:38\n",
       "729318    2016-02-22 00:43:11\n",
       "729319    2016-04-15 18:56:48\n",
       "729320    2016-06-19 09:50:47\n",
       "729321    2016-01-01 17:24:16\n",
       "Name: pickup_datetime, Length: 729322, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_tax['pickup_datetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2123a41",
   "metadata": {},
   "source": [
    "### 將Parquet文件加載到DataFrame中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a52fc423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 729322 entries, 0 to 729321\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  729322 non-null  object \n",
      " 1   vendor_id           729322 non-null  int64  \n",
      " 2   pickup_datetime     729322 non-null  object \n",
      " 3   dropoff_datetime    729322 non-null  object \n",
      " 4   passenger_count     729322 non-null  int64  \n",
      " 5   pickup_longitude    729322 non-null  float64\n",
      " 6   pickup_latitude     729322 non-null  float64\n",
      " 7   dropoff_longitude   729322 non-null  float64\n",
      " 8   dropoff_latitude    729322 non-null  float64\n",
      " 9   store_and_fwd_flag  729322 non-null  object \n",
      " 10  trip_duration       729322 non-null  int64  \n",
      "dtypes: float64(4), int64(3), object(4)\n",
      "memory usage: 61.2+ MB\n",
      "None\n",
      "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
      "0  id1080784          2  2016-02-29 16:40:21  2016-02-29 16:47:01   \n",
      "1  id0889885          1  2016-03-11 23:35:37  2016-03-11 23:53:57   \n",
      "2  id0857912          2  2016-02-21 17:59:33  2016-02-21 18:26:48   \n",
      "3  id3744273          2  2016-01-05 09:44:31  2016-01-05 10:03:32   \n",
      "4  id0232939          1  2016-02-17 06:42:23  2016-02-17 06:56:31   \n",
      "\n",
      "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
      "0                1        -73.953918        40.778873         -73.963875   \n",
      "1                2        -73.988312        40.731743         -73.994751   \n",
      "2                2        -73.997314        40.721458         -73.948029   \n",
      "3                6        -73.961670        40.759720         -73.956779   \n",
      "4                1        -74.017120        40.708469         -73.988182   \n",
      "\n",
      "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
      "0         40.771164                  N            400  \n",
      "1         40.694931                  N           1100  \n",
      "2         40.774918                  N           1635  \n",
      "3         40.780628                  N           1141  \n",
      "4         40.740631                  N            848  \n",
      "(729322, 11)\n"
     ]
    }
   ],
   "source": [
    "nyc_tax = pd.read_parquet('data/nyc_taxi_trip_duration.parquet')\n",
    "\n",
    "print(nyc_tax.info())\n",
    "print(nyc_tax.head())\n",
    "print(nyc_tax.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
