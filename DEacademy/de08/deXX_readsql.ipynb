{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff49654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.providers.amazon.aws.hooks.s3 import S3Hook\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from airflow.utils.dates import days_ago\n",
    "from airflow.exceptions import AirflowException\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "\n",
    "# download wikipedia pageviews data\n",
    "def get_data(s3_conn_id, bucket_name, object_key_prefix, pg_conn_id, sql, **context):\n",
    "    year, month, day, hour, *_ = context['execution_date'].timetuple()\n",
    "    # create postgres connection\n",
    "    pg_hook = PostgresHook(postgres_conn_id=pg_conn_id)\n",
    "    # get sqlalchemy engine instance\n",
    "    sqlalchemy_engine = pg_hook.get_sqlalchemy_engine()\n",
    "    try:\n",
    "        # dump dataframe to sql table via pandas.to_sql() method\n",
    "        df = pd.read_sql(sql, sqlalchemy_engine)\n",
    "        print(df.info())\n",
    "        print(df.head())\n",
    "    except Exception as e:\n",
    "        raise AirflowException(f\"read table to dataframe fail:{e}\")\n",
    "    # write rocket launch data to s3\n",
    "    with tempfile.NamedTemporaryFile('wb+') as fp:\n",
    "        temp_filename = fp.name  # 暫存檔案名\n",
    "        # use the same file hierarchy pattern\n",
    "        object_key = (\n",
    "            f\"{object_key_prefix}/de00_readsql:get_data/\"\n",
    "            f\"{year}/{year}-{month:0>2}/\"\n",
    "            f\"payment-{year}{month:0>2}{day:0>2}.csv.gz\"\n",
    "        )\n",
    "        try:\n",
    "            # export dataframe to csv\n",
    "            df.to_csv(temp_filename, index=False, compression='gzip')\n",
    "            # upload to s3\n",
    "            s3_hook = S3Hook(aws_conn_id=s3_conn_id)\n",
    "            s3_hook.load_file(filename=temp_filename,\n",
    "                              bucket_name=bucket_name,\n",
    "                              key=object_key,\n",
    "                              replace=True)\n",
    "            print(f'put query data to s3: [{bucket_name}] -> {object_key}, success!')\n",
    "        except Exception as e:\n",
    "            raise AirflowException(f\"put query data to s3 fail:{e}\")\n",
    "\n",
    "\n",
    "default_args = {\n",
    "    'owner':'EMPLOYEE_ID', # owner是DAG的開發者, 例如: 員工8703147\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    dag_id=\"deXX_readsql\", # prefix必需是tenant id, 例如: de00\n",
    "    description=\"dag to read dvdrental database to s3\",\n",
    "    start_date=days_ago(2),\n",
    "    schedule_interval=\"@daily\",\n",
    "    catchup=False,\n",
    "    max_active_runs=1,\n",
    "    default_args=default_args,\n",
    "    access_control={\n",
    "        'deXX': {'can_read', 'can_edit'} # 設定DAG歸屬那個團隊[tenant id]與權限\n",
    "    },\n",
    "    tags=['de08'],\n",
    ")\n",
    "\n",
    "sql_stmt = \"\"\"\n",
    "SELECT\n",
    "\tc.customer_id,\n",
    "\tc.first_name customer_first_name,\n",
    "\tc.last_name customer_last_name,\n",
    "\ts.first_name staff_first_name,\n",
    "\ts.last_name staff_last_name,\n",
    "\tamount,\n",
    "\tpayment_date\n",
    "FROM\n",
    "\tcustomer c\n",
    "INNER JOIN payment p \n",
    "    ON p.customer_id = c.customer_id\n",
    "INNER JOIN staff s \n",
    "    ON p.staff_id = s.staff_id\n",
    "ORDER BY payment_date;\n",
    "\"\"\"\n",
    "\n",
    "# task to download wikipedia pageviews data\n",
    "task_get_data = PythonOperator(\n",
    "    task_id='get_data',\n",
    "    python_callable=get_data,\n",
    "    op_kwargs={\n",
    "        's3_conn_id': 'deXX_minio',\n",
    "        'bucket_name': 'EMPLOYEE_ID',\n",
    "        'object_key_prefix': 'de08/dvdrental',\n",
    "        'pg_conn_id': 'dxlab_dvdrental',\n",
    "        'sql': sql_stmt,\n",
    "    },\n",
    "    dag=dag,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
